<<<<<<< HEAD
#  Screen Apnea â€“ Thermal-Based Respiration Monitoring & Apnea Detection System

_A non-contact thermal imaging system for respiration monitoring and shallow breathing detection using YOLOv8 and signal processing._

---

## ğŸ“Œ Table of Contents
- <a href="#overview">Overview</a>
- <a href="#problem-statement">Problem Statement</a>
- <a href="#dataset">Dataset</a>
- <a href="#tools--technologies">Tools & Technologies</a>
- <a href="#project-structure">Project Structure</a>
- <a href="#methodology">Methodology</a>
- <a href="#model-performance">Model Performance</a>
- <a href="#signal-validation--results">Signal Validation & Results</a>
- <a href="#key-insights">Key Insights</a>
- <a href="#sample-output">Sample Output</a>
- <a href="#how-to-run-this-project">How to Run This Project</a>
- <a href="#future-work">Future Work</a>
- <a href="#author--contact">Author & Contact</a>

---

<h2><a class="anchor" id="overview"></a>Overview</h2>

This project presents a **non-contact respiration monitoring system** using thermal imaging.  
The objective is to build an affordable, privacy-friendly solution capable of detecting shallow breathing and apnea-related anomalies without wearable sensors.

The project was developed in two phases:

- **Phase 1 â€“ Screen Apnea**
  - 12 participants
  - YOLOv8-based nostril detection
  - Respiration signal extraction
  - Chest belt validation (4 participants)

- **Phase 2 â€“ Extended Respiration Study**
  - 45 participants
  - Full-length respiration pattern extraction
  - Foundation for apnea event classification

---

<h2><a class="anchor" id="problem-statement"></a>Problem Statement</h2>

Traditional apnea detection systems:

- Require wearable devices (chest belts, nasal cannula)
- Are uncomfortable for long-term use
- Operate mostly in lab-controlled environments
- Have high setup costs

This project aims to develop:

- A non-contact respiration monitoring system
- Real-time nostril detection in thermal images
- Frequency-based respiration validation
- Edge-device compatible solution

---

<h2><a class="anchor" id="dataset"></a>Dataset</h2>

### Phase 1 â€“ Screen Apnea
- 12 participants
- 10â€“15 minutes recording per participant
- Thermal recordings using TOPDON TC View
- Chest belt ground truth for 4 participants

### Phase 2 â€“ Extended Study
- 45 participants
- 3500+ annotated thermal frames
- Long-duration respiration extraction

---

<h2><a class="anchor" id="tools--technologies"></a>Tools & Technologies</h2>

- Python
- YOLOv8 (Ultralytics)
- OpenCV
- NumPy
- SciPy (Signal Processing)
- Label Studio (Annotation)
- Jupyter Notebook
- Thermal Camera (TOPDON TC View)
- Git & GitHub

---

<h2><a class="anchor" id="project-structure"></a>Project Structure</h2>

```
ScreenApnea/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitattributes
â”‚
â”œâ”€â”€ CollectedData/
â”‚   â”œâ”€â”€ Gajendra2025-02-1615-03-39.avi
â”‚   â””â”€â”€ thermalvideo.txt
â”‚
â”œâ”€â”€ Frameextraction/
â”‚   â””â”€â”€ 01gajframes/
â”‚       â”œâ”€â”€ 01frame[0-261].png            (~262 files)
â”‚       â””â”€â”€ 01varied[22-258].png          (~150 files)
â”‚
â”œâ”€â”€ Resultanalysisallfile/
â”‚   â”œâ”€â”€ P011/  (*.csv: EXP-1*, ex1*, meanpixel*, processedchestresp)
â”‚   â”œâ”€â”€ P012/  (*.csv: EXP-2*, ex2*, downsample*, exp2)
â”‚   â”‚          graphs.png
â”‚   â”‚          thermalrec2.avi
â”‚   â”œâ”€â”€ P013/  (*.csv: EXP-3*, ex3*)
â”‚   â”‚          output.png
â”‚   â”‚          thermalrec3.avi
â”‚   â””â”€â”€ P014/  (*.csv: EXP-4*, ex4*)
â”‚              thermalrec4.avi
â”‚
â”œâ”€â”€ YOLOModelTraining/
â”‚   â”œâ”€â”€ .venv/Lib/site-packages/          (pip packages, *.pyc, *.py â€“ thousands)
â”‚   â”œâ”€â”€ best.pt
â”‚   â”œâ”€â”€ data.yaml
â”‚   â”œâ”€â”€ *.ipynb                           (main100, mean, mean1, sc)
â”‚   â”‚
â”‚   â”œâ”€â”€ runs/
â”‚   â”‚   â”œâ”€â”€ detect/
â”‚   â”‚   â””â”€â”€ train[1-8]/
â”‚   â”‚       â”œâ”€â”€ args.yaml (x8)
â”‚   â”‚       â”œâ”€â”€ events.out.tfevents.* (x8)
â”‚   â”‚       â””â”€â”€ labels.jpg (x8)
â”‚   â”‚
â”‚   â”œâ”€â”€ train/images/                     (~400 files)
â”‚   â”‚   â”œâ”€â”€ 01frame[0-261].png
â”‚   â”‚   â””â”€â”€ 01varied*
â”‚   â”‚
â”‚   â”œâ”€â”€ test/images/                      (~200 files)
â”‚   â”‚   â”œâ”€â”€ 01-12frame*
â”‚   â”‚   â””â”€â”€ 01-12varied*
â”‚   â”‚
â”‚   â””â”€â”€ labels/                           (~2000 files)
â”‚       â”œâ”€â”€ 01-12frame*.txt
â”‚       â””â”€â”€ 01-12varied*.txt
```
---

<h2><a class="anchor" id="methodology"></a>Methodology</h2>

### 1ï¸âƒ£ Data Collection
- Thermal video recording of face region
- Natural sitting/sleeping conditions
- Chest belt ground truth (subset)

### 2ï¸âƒ£ Frame Extraction & Annotation
- Extracted frames from thermal videos
- Manual nostril ROI annotation
- Created 3500+ labeled images

### 3ï¸âƒ£ Model Training â€“ YOLOv8

Trained multiple configurations:

- Image Size: 640, 1280
- Epochs: 100â€“300
- Augmentation enabled/disabled

Evaluation Metrics:

- Precision
- Recall
- mAP@0.5
- mAP@0.5:0.95

### 4ï¸âƒ£ Respiration Signal Extraction

- Detect nostril ROI
- Extract mean pixel intensity per frame
- Downsample to 20 Hz
- Apply bandpass filter (0.1â€“0.5 Hz)

---

<h2><a class="anchor" id="model-performance"></a>Model Performance</h2>

Final Model: **YOLOv8n (Train_2 Configuration)**

- mAP@0.5 = 0.978
- mAP@0.5:0.95 = 0.815
- Real-time detection capability
- Suitable for edge deployment

---

<h2><a class="anchor" id="signal-validation--results"></a>Signal Validation & Results</h2>

- 20-second window segmentation
- 120 total windows analyzed
- Compared thermal frequency vs chest belt frequency

Results:

- Mean MAE: 0.31 Hz
- Mean RMSE: 0.31 Hz
- Strong correlation with ground truth
- Filtering reduced error by ~50% in some participants

---

<h2><a class="anchor" id="key-insights"></a>Key Insights</h2>

- Thermal nostril ROI can accurately estimate respiration frequency
- Bandpass filtering significantly improves signal clarity
- Errors remained minimal in most windows
- Real-time inference is feasible
- Non-contact monitoring works in natural environments

---

<h2><a class="anchor" id="sample-output"></a>Sample Output</h2>

```markdown
![Respiration Signal](output.png)
```

Or resize using HTML:

```html
<img src="output.png" width="600">
```

---

<h2><a class="anchor" id="how-to-run-this-project"></a>How to Run This Project</h2>

1. Clone repository:

```bash
git clone https://github.com/gajendramandal/Screen_Apnea.git
cd Screen_Apnea
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run YOLO detection:

```bash
yolo detect predict model=YOLOModelTraining/best.pt source=video.mp4
```

4. Run signal processing notebook:

Open:

```
Frameextraction/main_1_0_0.ipynb
```

---

<h2><a class="anchor" id="future-work"></a>Future Work</h2>

- Apnea event annotation
- AHI estimation
- Severity classification
- Multi-ROI fusion (nostril + chest)
- Clinical validation
- Real-time embedded deployment

---

<h2><a class="anchor" id="author--contact"></a>Author & Contact</h2>

**Gajendra Mandal**  
B.Tech (Hons.) Data Science  
IIT Gandhinagar (Internship Project)  

ğŸ”— GitHub: https://github.com/gajendramandal  
ğŸ“§ Email: gajendramandal2003@gmail.com
=======
# Screen_Apnea
```
ScreenApnea/
.gitattributes
CollectedData/
â”œâ”€â”€ Gajendra2025-02-1615-03-39.avi
â””â”€â”€ thermalvideo.txt
Frameextraction/
â””â”€â”€ 01gajframes/
    â”œâ”€â”€ 01frame[0-261].png (~262 files)
    â””â”€â”€ 01varied[22-258].png (~150 files)
Resultanalysisallfile/
â”œâ”€â”€ P011/ (*.csv: EXP-1*, ex1*, meanpixel*, processedchestresp)
â”œâ”€â”€ P012/ (*.csv: EXP-2*, ex2*, downsample*, exp2; graphs.png, thermalrec2.avi)
â”œâ”€â”€ P013/ (*.csv: EXP-3*, ex3*; output.png, thermalrec3.avi)
â””â”€â”€ P014/ (*.csv: EXP-4*, ex4*; thermalrec4.avi)
YOLOModelTraining/
â”œâ”€â”€ .venv/Lib/site-packages/ (pip packages, *.pyc, *.py - thousands)
â”œâ”€â”€ best.pt
â”œâ”€â”€ *.ipynb (main100, mean, mean1, sc)
â”œâ”€â”€ data.yaml
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ detect/
â”‚   â””â”€â”€ train[1-8]/ (args.yaml x8, events.out.tfevents.* x8, labels.jpg x8)
â”œâ”€â”€ test/images/ (*.png: 01-12frame*, 01-12varied* - ~200 files)
â”œâ”€â”€ labels/ (*.txt: 01-12frame*, 01-12varied* - ~2000 files)
â””â”€â”€ train/images/ (01frame[0-261].png, 01varied* - ~400 files)
README.md
```
>>>>>>> b1cf2951c1b0af4d085896d40caceae4e24415c9

